{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import helpers as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fss(tokens, pos, neg):\n",
    "    \"\"\"\n",
    "    Calcula Financial Stability Sentiment index basado en tokens de un documento.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: list or iterable\n",
    "    pos: set\n",
    "    neg: set\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    float\n",
    "    \"\"\"\n",
    "    fd = Counter(tokens)\n",
    "\n",
    "    emopos = sum(c for w, c in fd.items() if w in pos)\n",
    "    emoneg = sum(c for w, c in fd.items() if w in neg)\n",
    "    total = sum(fd.values())\n",
    "\n",
    "    emodiff = emoneg - emopos\n",
    "\n",
    "    try:\n",
    "        score = (emodiff / total)\n",
    "    except ZeroDivisionError:\n",
    "        score = np.nan\n",
    "    except Exception as e:\n",
    "        score = np.nan\n",
    "        logging.info('ERROR inesperado calculando FSS: {}'.format(e))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_corpus = '/Users/tombito/Downloads/estabilidad/reportes/en/corpus/'\n",
    "dir_output = 'isref'\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "pathstops = '/Users/tombito/Dropbox/datasets/wordlists/stopwords/stopwords.xlsx'\n",
    "wdlist = '/Users/tombito/Dropbox/datasets/wordlists/fss.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wdlist, encoding='utf-8') as f:\n",
    "    diction = json.load(f, encoding='utf-8')\n",
    "\n",
    "positive = diction.get('positive')\n",
    "negative = diction.get('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = hp.load_stopwords(pathstops, 'english', col='word')\n",
    "tags = ['NOUN', 'VERB', 'ADJ', 'ADV', 'ADP','AUX', 'DET', 'PRON']\n",
    "ents = ['PER', 'ORG']\n",
    "\n",
    "extra = dict(stopwords=stops, postags=tags, entities=ents, ) \n",
    "# opcional stemmer=SnowballStemmer('spanish')\n",
    "# habiendo importado from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngramas = hp.model_ngrams(hp.iter_sentences(dir_corpus, nlp, extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docnames = hp.get_docnames(dir_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [fss(words, positive, negative) \n",
    "          for words in hp.iter_documents(ngramas, dir_corpus, nlp, extra)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "isref = pd.DataFrame({'doc': docnames, 'score': scores})\n",
    "isref.to_csv(os.path.join(dir_output, 'isref.csv'), index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>-0.003219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>-0.008579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          doc     score\n",
       "0  2002-12-01 -0.003219\n",
       "1  2003-07-01 -0.008579"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
